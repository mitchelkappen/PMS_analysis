{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "31a278dc-401c-40ee-9f63-67f3c4045753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ae946-7c42-40f3-85a2-9da0355a1ee5",
   "metadata": {},
   "source": [
    "# What's happening here?\n",
    "\n",
    "In this notebook we will read in all the csv files and compile it to useful information. \n",
    "We will end up with comprehensive CSV files containing all usefull information. \n",
    "\n",
    "Add to this list:\n",
    "- Responses\n",
    "- RT\n",
    "- Testmoment\n",
    "- Ppt number\n",
    "- Total time taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c335d2-397b-4ecc-b625-e15d4cd4f851",
   "metadata": {},
   "source": [
    "Make list\n",
    "Check for all instances with that name\n",
    "if exists: wCam\n",
    "- get that\n",
    "else:\n",
    "- get other\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d621263-d223-4c96-a89e-9425b09dea93",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb795486-621d-4457-a2d0-1584d3ab5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare all directories:\n",
    "\n",
    "data_dir = Path('Z:/shares/ghepmk_data/2020_Kappen_PMS')\n",
    "\n",
    "# Create all relevant directories\n",
    "date_dir = \"24082021/\"\n",
    "data_all_dir = os.path.join(data_dir, date_dir)\n",
    "data_A_dir = os.path.join(data_dir, Path('10001'))\n",
    "data_B_dir = os.path.join(data_dir, Path('10002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bbcd1a1-0e34-4c56-86e3-535a0558ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_A_dir)\n",
    "ACsv = glob.glob(\"csv/\" + \"*ParticipantNo*\" + \"*.csv\", recursive = True) # get all csv's in directory\n",
    "ACsvID = []\n",
    "CSVy_n = []\n",
    "substring = \"wCAM\" # This is only present in some files but is prefered\n",
    "\n",
    "for index, item in enumerate(ACsv):\n",
    "    ACsvID.append(ACsv[index].split(\"data_{ParticipantNo}_\")[1][0:3])\n",
    "    if substring in ACsv[index]:\n",
    "        CSVy_n.append(True)\n",
    "    else:\n",
    "        CSVy_n.append(False)\n",
    "        \n",
    "# ACsvID = set(ACsvID)\n",
    "\n",
    "# demographics = pd.read_csv(\"Z:/shares/ghepmk_data/2020_Kappen_PMS/24082021/cleanData.csv\", encoding = \"ISO-8859-1\")\n",
    "demographics = pd.read_csv(data_all_dir + \"cleanData.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "43ecfd6d-32b2-478e-a448-ef1c2f37e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['203', # Double moment A\n",
    "           '262', # Double moment A\n",
    "           '285', # Double moment A (both wCAM)\n",
    "           '334', # Double moment A\n",
    "           '312', # Double moment A\n",
    "           '361', # Double moment A, but second time moment A also did moment B (2 days later).\n",
    "           '531', # Double moment A\n",
    "           '661', # Double moment A, but second time moment A also did moment B.\n",
    "           '667', # Double moment A, but second time moment A also did moment B. Only 4 days between moment A and B, figure out\n",
    "           \n",
    "           '105', # No demographics present. First known participant number is 129. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '106', # No demographics present. First known participant number is 129. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '107', # No demographics present. First known participant number is 129. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '118', # No demographics present. First known participant number is 129. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '119', # No demographics present. First known participant number is 129. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '123', # No demographics present. First known participant number is 129. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '127', # No demographics present. First known participant number is 129. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '778', # No demographics present. Last known participant number is 677. So probably wrong participant number. Figure out and then -> change name of csv/webm\n",
    "           '999', # No demographics present. Last known participant number is 677. So probably a testing round\n",
    "           '998', # No demographics present. Last known participant number is 677. So probably a testing round\n",
    "           \n",
    "           '407', # Double demographics entry (seems like they first filled out with wrong mentrual duration) - figure this out\n",
    "           \n",
    "           '66_', # Weird participant number, let's see if we can figure out what the correct one would've been here -> change name of csv/webm\n",
    "           '6_1', # Very hacky, because if the particpiant ends in '6' and date starts with '1' this will also get triggered. Figure out how this ends up in the csv file and try to solve\n",
    "           '&à&', # Weird stuff, shouldn't be here\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97296c5-4937-4194-b5eb-55ab5315a2c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▏                                                        | 194/670 [00:20<00:38, 12.31it/s]"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for pptnum in tqdm(ACsvID): # Loop through all file ID's\n",
    "#     print(\"Processing: \" + pptnum)\n",
    "    if pptnum not in exclude: # Some participants messed up, so skip those. See earlier cell for descriptions of each\n",
    "        index += 1\n",
    "        # Find right file to load and read_csv in\n",
    "        indices = [i for i, s in enumerate(ACsv) if pptnum in s and \"wCAM\" not in s] # Check if there is a file WITHOUT wCAM because that is preferred (saved later)\n",
    "        if len(indices) == 1: # if one, that is perfect, read it\n",
    "            data = pd.read_csv(ACsv[indices[0]])\n",
    "        if len(indices) > 1: # if more than one, something is going wrong, figure out\n",
    "            print(\"Too many .csv files for ppt \" + pptnum + \".\")\n",
    "            break\n",
    "        elif len(indices) == 0: # if none, probably only saved before video, so check wCAM\n",
    "            indices = [i for i, s in enumerate(ACsv) if pptnum in s and \"wCAM\" in s] # Find instances where files exist WITH wCAM\n",
    "            if len(indices) == 1: # if one, that is perfect, read it\n",
    "                data = pd.read_csv(ACsv[indices[0]])\n",
    "            if len(indices) > 1: # if more than one, something is going wrong, figure out\n",
    "                print(\"Too many wCAM.csv files for ppt \" + pptnum + \".\")\n",
    "                break\n",
    "            elif len(indices) == 0: # If none, something weird is happening, as it should have appeared here then\n",
    "                print(\"No wCAM.csv files for ppt \" + pptnum + \".\")\n",
    "                break\n",
    "\n",
    "        #  Now check whether they completed the experiment\n",
    "        if not data['stimulus'].str.contains('beep.wav').any(): # if beep.wav is present (final thing in the experiment) they finished\n",
    "            print(\"ppt \" + pptnum + \" did not finish the experiment.\")\n",
    "            break\n",
    "\n",
    "        # Get data in Demographics file\n",
    "    #     demoindex = [i for i, s in enumerate(demographics['participantNo'] == int(pptnum)) if s][0]\n",
    "        demoindex = np.where(demographics['participantNo'] == int(pptnum))[0]\n",
    "        if len(demoindex) > 1: # Too many entries for this ppt\n",
    "            print(\"Too many demographics entries for ppt \" + pptnum + \".\")\n",
    "            break\n",
    "        elif len(demoindex) == 0:\n",
    "            print(\"No demographics entries for ppt \" + pptnum + \".\")\n",
    "            break\n",
    "        elif len(demoindex) == 1:\n",
    "            # Create indices for the trial selections\n",
    "            indices = [i for i, s in enumerate(data['trial_type']) if \"image-keyboard-response\" in s]\n",
    "            indices2 = [x+1 for x in indices]\n",
    "            stimNum = len(indices) # to add constant values to dataframe\n",
    "\n",
    "            # Get correct PSS and BSRI values\n",
    "            statementAB = demographics['Order'][demoindex].apply(str) == \"A-B\"\n",
    "            statementBA = demographics['Order'][demoindex].apply(str) == \"B-A\"\n",
    "\n",
    "            if statementAB.bool() == True: # If order is A-B, and this is moment A, then A is folliculair\n",
    "                PSS = demographics['folliculairPSS'][demoindex].values[0]\n",
    "                BSRI = demographics['folliculairBSRI'][demoindex].values[0]\n",
    "            elif statementBA.bool() == True: # If order is B-A, and this is moment A, then A is folliculair\n",
    "                PSS = demographics['luteaalPSS'][demoindex].values[0]\n",
    "                BSRI = demographics['luteaalBSRI'][demoindex].values[0]\n",
    "            else:\n",
    "                print(\"ppt \" + pptnum + \" does not have a valid experiment order.\")\n",
    "\n",
    "            df = pd.DataFrame(list(zip([pptnum] * stimNum, [demographics['Age'][demoindex].values[0]] * stimNum, [demographics['FirstMenstrual'][demoindex].values[0]] * stimNum, [demographics['MenstrualDuration'][demoindex].values[0]] * stimNum,\n",
    "                                       [demographics['Order'][demoindex].values[0]] * stimNum, [demographics['allSymptoms'][demoindex].values[0]] * stimNum, [demographics['allDisturbance'][demoindex].values[0]] * stimNum, [demographics['allRRS'][demoindex].values[0]] * stimNum,\n",
    "                                       [demographics['DASS.Total'][demoindex].values[0]] * stimNum, [demographics['DASS.Stress'][demoindex].values[0]] * stimNum, [demographics['DASS.Anxiety'][demoindex].values[0]] * stimNum, [demographics['DASS.Depresh'][demoindex].values[0]] * stimNum,\n",
    "                                       [demographics['PMSScore'][demoindex].values[0]] * stimNum, [demographics['Contraception'][demoindex].values[0]] * stimNum, [PSS] * stimNum, [BSRI] * stimNum,\n",
    "                                       data['stimulusShort'][indices], data['valence'][indices2], data['arousal'][indices2], data['rt'][indices2], )),\n",
    "                           columns =['ID', 'Age', 'FirstMenstrual', 'MenstrualDuration', \n",
    "                                     'Order', 'allSymptoms', 'allDistrubance', 'allRRS', \n",
    "                                     'DASS_Total', 'DASS_Stress', 'DASS_Anxiety', 'DASS_Depression', \n",
    "                                     'PMSScore', 'Contraception', 'PSS', 'BSRI',\n",
    "                                     'Stimulus', 'Valence', 'Arousal', 'rt'])\n",
    "        if index == 1:\n",
    "            dataset = df\n",
    "        else:\n",
    "            dataset = pd.concat([dataset, df], ignore_index=True)\n",
    "    #         break\n",
    "# dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
