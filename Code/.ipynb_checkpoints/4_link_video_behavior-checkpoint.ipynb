{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a599427c-70ba-42e3-85fd-dca7d7d7f116",
   "metadata": {},
   "source": [
    "# What's happening here?\n",
    "\n",
    "4_link_video_behavior.ipynb\n",
    "\n",
    "Run after 1_, 2_, and 3_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e3393-2206-400e-9b4f-e97860ffc57b",
   "metadata": {},
   "source": [
    "Made in environment **PMS_Study**\n",
    "\n",
    "## TO DO: bekijk file PMS_analysis/2_preparation\n",
    "\n",
    "Probeer veel met loops en functions te werken om de code overzichtelijk te houden\n",
    "\n",
    " * Start with file cleanData.csv (geeft informatie over van welke participant welke files bestaan)\n",
    " * Load timings.csv file that Tilia and Sofie made\n",
    " * Start loop from the top and use Order and A-B\n",
    " * In loop check if file (corresponding CSV) exists in Directory (/10001 or /10002 depedent of A/B): later refered to as behaviordata\n",
    " * In loop check if file (corresponding .WEBM) exists in Directory\n",
    " \n",
    "If both exist:\n",
    "- Check if output of Openface exists in Z:\\shares\\ghepmk_data\\2020_Kappen_PMS\\10002\\video_features (or /10001 dependent of A/B)\n",
    "- IF True:\n",
    "Load this as facedata\n",
    "- IF False:\n",
    "Print: \"Video file present for file (insert filename) but no openface present)\"\n",
    "Break/skip\n",
    "\n",
    "Use filename/pptnum to search for right starting time in timings.csv variable\n",
    "- Find timing for beep.wav in behaviordata. \n",
    "- Set new zero point (link between the timings.csv point and this)\n",
    "- Make mean scores on a few variables (we will expand this later) for the corresponding frames of each of the trials.\n",
    "- To do this, you should write a function that takes the right points of a trial (start, end, trialnum etc) and save this data to a dataframe\n",
    "\n",
    "Compute this in a way that you would be able to add it to allPMSdata.cvs\n",
    "\n",
    "Add it all to a new dataframe\n",
    "\n",
    "Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5439c6-64af-4bc7-9e84-900f8dfb6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "import features as ft\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e11c38-e968-46b7-8f43-fa5976c54e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all relevant directories\n",
    "data_dir = Path('Z:/shares/ghepmk_data/2020_Kappen_PMS')\n",
    "date_dir = \"06102021/\"\n",
    "data_all_dir = os.path.join(data_dir, date_dir)\n",
    "\n",
    "# Load base data\n",
    "demographics = pd.read_csv(data_all_dir + \"cleanData.csv\", encoding = \"ISO-8859-1\")\n",
    "allData = pd.read_csv(data_all_dir + \"allPMSdata.csv\", encoding = \"ISO-8859-1\")\n",
    "timings = pd.read_csv(data_all_dir + \"timings.csv\", encoding = \"ISO-8859-1\")\n",
    "timings = timings.rename(columns={\"ï»¿ImageGroup\": \"ImageGroup\"}, index={'ONE': 'Row_1'}) # Rename first column, because was formatted weird\n",
    "\n",
    "redoOpenface = 0 # Set to 1 if you want to re-do OpenFace processing. For instance if you added features, or changed methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c9098d-fc3a-4451-ad0c-d330c5e8ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all OpenFace files\n",
    "os.chdir(data_dir)\n",
    "AFiles = glob.glob(\"10001/video_features/\" + \"*ParticipantNo*\" + \"*.csv\", recursive = True) # get all csv's in directory\n",
    "BFiles = glob.glob(\"10002/video_features/\" + \"*ParticipantNo*\" + \"*.csv\", recursive = True) # get all csv's in directory\n",
    "\n",
    "# Opening JSON file with all video duration information\n",
    "f = open(data_all_dir + 'video_durations.json',)\n",
    "durationsdata = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fce032a-3a1c-4259-88ac-f66c1c95d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openfacestuff(fileDir):\n",
    "    print(fileDir)\n",
    "    if len(indices) > 1:\n",
    "        print(\"Too many OpenFace files for ppt: \" + str(pptnum) + \" at moment \" + moment)\n",
    "    else: # If we get to here - the party really starts\n",
    "        try:\n",
    "            math.isnan(allData['AU12'][idx[0]])\n",
    "        except:\n",
    "            allData[\"AU12\"] = np.nan # In case this column doesn't exist yet, create a column with only nan's so th next if statement always passes\n",
    "            \n",
    "        if math.isnan(allData['AU12'][idx[0]]) or redoOpenface == 1: # Check if OpenFace values have already been added, of whether manually set at top of script to re do this (so it doesnt happen unneccessarily\n",
    "            openface = pd.read_csv(fileDir, encoding = \"ISO-8859-1\") # Read openface output csv\n",
    "\n",
    "            # Get corresponding video file duration \n",
    "            splits = fileDir.split('/video_features\\\\')\n",
    "            fileduration = [value for key, value in durationsdata.items() if splits[0] in key.lower() and splits[1][23:len(splits[1])-4] in key.lower()] # Very weird formatting, but when checking for directory (10001/10002) and only the date (something with curly bracktes messes it up. \n",
    "            frameduration = fileduration[0] / len(openface)\n",
    "            openface.insert (3, \"timestamp2\", np.arange(0, fileduration[0], frameduration).tolist()[0:len(openface)]) # Add new timestamps right after the first timestamp || We're taking [0:len(openface)] here because due to rounding error, the newly created timestamps might be one longer than th array. \n",
    "            videoOffset\n",
    "            behaviorOffset = allData['startBeep'][idx[0]]\n",
    "            correctedStarts = allData['startView'][idx] - behaviorOffset # startViews - offSet\n",
    "            videoStarts = ((correctedStarts + videoOffset) / 1000).tolist() # These will be the timestamps in seconds because / 1000\n",
    "\n",
    "            correctedEnds = allData['stopView'][idx] - behaviorOffset # startViews - offSet\n",
    "            videoEnds = ((correctedEnds + videoOffset) / 1000).tolist()\n",
    "            \n",
    "            print(videoStarts)\n",
    "\n",
    "            # Loop over all the trials and get the appropriate values - add to allData\n",
    "            for trial in range(0,len(videoStarts)):\n",
    "                vidStartIdx = openface.iloc[(openface['timestamp2']-videoStarts[trial]).abs().argsort()[:1]].index.tolist()[0] # Get start idx in openface\n",
    "                vidEndIdx = openface.iloc[(openface['timestamp2']-videoEnds[trial]).abs().argsort()[:1]].index.tolist()[0] # Get end idx in openface\n",
    "\n",
    "                # Create mean value between these idx's and add to big dataframe\n",
    "                allData.loc[idx[trial], 'AU12'] = openface[' AU12_r'][vidStartIdx:vidEndIdx].mean() \n",
    "                allData.loc[idx[trial], 'AU15'] = openface[' AU15_r'][vidStartIdx:vidEndIdx].mean() \n",
    "                \n",
    "                allData.loc[idx[trial], 'arousal'] = ft.compute_arousal(openface[vidStartIdx:vidEndIdx])['mean_Arousal']\n",
    "#                 allData.loc[idx[trial], 'blinkrate'] = ft.compute_blink_rate(openface[vidStartIdx:vidEndIdx])\n",
    "                allData.loc[idx[trial], 'PD_Mean'] = ft.compute_PD_features(openface[vidStartIdx:vidEndIdx])['mean_PD']\n",
    "                allData.loc[idx[trial], 'PD_Std'] = ft.compute_PD_features(openface[vidStartIdx:vidEndIdx])['std_PD']\n",
    "                allData.loc[idx[trial], 'PD_Max'] = ft.compute_PD_features(openface[vidStartIdx:vidEndIdx])['max_PD']\n",
    "                \n",
    "                allData.loc[idx[trial], 'headMovement'] = ft.compute_head_motion(openface[vidStartIdx:vidEndIdx])['compound_Motion']\n",
    "\n",
    "                allData.loc[idx[trial], 'happy'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Happy']\n",
    "                allData.loc[idx[trial], 'sad'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Sad']\n",
    "                allData.loc[idx[trial], 'disgust'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Disgust']\n",
    "                allData.loc[idx[trial], 'anger'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Angry']\n",
    "                allData.loc[idx[trial], 'scared'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Scared']\n",
    "                \n",
    "                allData.loc[idx[trial], 'confidence'] = ft.compute_quality(openface[vidStartIdx:vidEndIdx])['mean_confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07249d9e-24e6-4978-b21d-039f5c6df973",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▌                                                                  | 89/525 [00:00<00:00, 806.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing pptnum: 14\n",
      "Exclusion file for ppt: 14 at moment: B\n",
      "processing pptnum: 66\n",
      "Exclusion file for ppt: 66 at moment: B\n",
      "processing pptnum: 106\n",
      "No input data found for video file of pptnum: 106 with video file B\n",
      "processing pptnum: 119\n",
      "No input data found for video file of pptnum: 119 with video file B\n",
      "processing pptnum: 123\n",
      "No input data found for video file of pptnum: 123 with video file B\n",
      "processing pptnum: 124\n",
      "No input data found for video file of pptnum: 124 with video file B\n",
      "processing pptnum: 125\n",
      "No input data found for video file of pptnum: 125 with video file B\n",
      "processing pptnum: 126\n",
      "No input data found for video file of pptnum: 126 with video file B\n",
      "processing pptnum: 127\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 129\n",
      "10002/video_features\\video_{ParticipantNo}_129_9-10-2020.csv\n",
      "processing pptnum: 131\n",
      "10002/video_features\\video_{ParticipantNo}_131_2-11-2020.csv\n",
      "processing pptnum: 134\n",
      "10002/video_features\\video_{ParticipantNo}_134_16-10-2020.csv\n",
      "processing pptnum: 135\n",
      "10002/video_features\\video_{ParticipantNo}_135_5-10-2020.csv\n",
      "processing pptnum: 140\n",
      "10002/video_features\\video_{ParticipantNo}_140_31-10-2020.csv\n",
      "processing pptnum: 144\n",
      "10002/video_features\\video_{ParticipantNo}_144_15-11-2020.csv\n",
      "processing pptnum: 145\n",
      "10002/video_features\\video_{ParticipantNo}_145_15-11-2020.csv\n",
      "processing pptnum: 147\n",
      "10002/video_features\\video_{ParticipantNo}_147_9-11-2020.csv\n",
      "processing pptnum: 148\n",
      "10002/video_features\\video_{ParticipantNo}_148_17-11-2020.csv\n",
      "processing pptnum: 154\n",
      "10002/video_features\\video_{ParticipantNo}_154_13-11-2020.csv\n",
      "processing pptnum: 155\n",
      "10002/video_features\\video_{ParticipantNo}_155_12-11-2020.csv\n",
      "processing pptnum: 156\n",
      "10002/video_features\\video_{ParticipantNo}_156_31-10-2020.csv\n",
      "processing pptnum: 157\n",
      "10002/video_features\\video_{ParticipantNo}_157_17-11-2020.csv\n",
      "processing pptnum: 158\n",
      "10002/video_features\\video_{ParticipantNo}_158_15-12-2020.csv\n",
      "processing pptnum: 159\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 161\n",
      "10002/video_features\\video_{ParticipantNo}_161_11-11-2020.csv\n",
      "processing pptnum: 163\n",
      "10002/video_features\\video_{ParticipantNo}_163_9-11-2020.csv\n",
      "processing pptnum: 165\n",
      "10002/video_features\\video_{ParticipantNo}_165_5-12-2020.csv\n",
      "processing pptnum: 166\n",
      "10002/video_features\\video_{ParticipantNo}_166_9-11-2020.csv\n",
      "processing pptnum: 167\n",
      "10002/video_features\\video_{ParticipantNo}_167_15-11-2020.csv\n",
      "processing pptnum: 168\n",
      "10002/video_features\\video_{ParticipantNo}_168_18-11-2020.csv\n",
      "processing pptnum: 169\n",
      "10002/video_features\\video_{ParticipantNo}_169_10-12-2020.csv\n",
      "processing pptnum: 170\n",
      "Exclusion file for ppt: 170 at moment: B\n",
      "processing pptnum: 171\n",
      "10002/video_features\\video_{ParticipantNo}_171_9-11-2020.csv\n",
      "processing pptnum: 172\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 173\n",
      "10002/video_features\\video_{ParticipantNo}_173_18-11-2020.csv\n",
      "processing pptnum: 176\n",
      "10002/video_features\\video_{ParticipantNo}_176_26-11-2020.csv\n",
      "processing pptnum: 177\n",
      "10002/video_features\\video_{ParticipantNo}_177_12-11-2020.csv\n",
      "processing pptnum: 178\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 180\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 181\n",
      "10002/video_features\\video_{ParticipantNo}_181_22-11-2020.csv\n",
      "processing pptnum: 182\n",
      "10002/video_features\\video_{ParticipantNo}_182_21-11-2020.csv\n",
      "processing pptnum: 185\n",
      "10002/video_features\\video_{ParticipantNo}_185_4-12-2020.csv\n",
      "processing pptnum: 187\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 189\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 193\n",
      "10002/video_features\\video_{ParticipantNo}_193_3-11-2020.csv\n",
      "processing pptnum: 194\n",
      "10002/video_features\\video_{ParticipantNo}_194_19-11-2020.csv\n",
      "processing pptnum: 195\n",
      "10002/video_features\\video_{ParticipantNo}_195_4-12-2020.csv\n",
      "processing pptnum: 197\n",
      "10002/video_features\\video_{ParticipantNo}_197_13-12-2020.csv\n",
      "processing pptnum: 198\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 199\n",
      "10002/video_features\\video_{ParticipantNo}_199_18-11-2020.csv\n",
      "processing pptnum: 200\n",
      "10002/video_features\\video_{ParticipantNo}_200_11-11-2020.csv\n",
      "processing pptnum: 201\n",
      "10002/video_features\\video_{ParticipantNo}_201_30-11-2020.csv\n",
      "processing pptnum: 206\n",
      "10002/video_features\\video_{ParticipantNo}_206_2-11-2020.csv\n",
      "processing pptnum: 207\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 211\n",
      "10002/video_features\\video_{ParticipantNo}_211_17-11-2020.csv\n",
      "processing pptnum: 214\n",
      "10002/video_features\\video_{ParticipantNo}_214_11-12-2020.csv\n",
      "processing pptnum: 215\n",
      "10002/video_features\\video_{ParticipantNo}_215_22-11-2020.csv\n",
      "processing pptnum: 216\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 221\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 222\n",
      "10002/video_features\\video_{ParticipantNo}_222_5-11-2020.csv\n",
      "processing pptnum: 223\n",
      "10002/video_features\\video_{ParticipantNo}_223_1-12-2020.csv\n",
      "processing pptnum: 224\n",
      "10002/video_features\\video_{ParticipantNo}_224_5-11-2020.csv\n",
      "processing pptnum: 225\n",
      "10002/video_features\\video_{ParticipantNo}_225_27-11-2020.csv\n",
      "processing pptnum: 226\n",
      "10002/video_features\\video_{ParticipantNo}_226_5-11-2020.csv\n",
      "processing pptnum: 227\n",
      "10002/video_features\\video_{ParticipantNo}_227_10-12-2020.csv\n",
      "processing pptnum: 230\n",
      "10002/video_features\\video_{ParticipantNo}_230_7-11-2020.csv\n",
      "processing pptnum: 231\n",
      "10002/video_features\\video_{ParticipantNo}_231_18-11-2020.csv\n",
      "processing pptnum: 233\n",
      "10002/video_features\\video_{ParticipantNo}_233_4-11-2020.csv\n",
      "processing pptnum: 239\n",
      "10002/video_features\\video_{ParticipantNo}_239_2-12-2020.csv\n",
      "processing pptnum: 241\n",
      "10002/video_features\\video_{ParticipantNo}_241_11-12-2020.csv\n",
      "processing pptnum: 242\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 243\n",
      "10002/video_features\\video_{ParticipantNo}_243_18-11-2020.csv\n",
      "processing pptnum: 246\n",
      "10002/video_features\\video_{ParticipantNo}_246_14-11-2020.csv\n",
      "processing pptnum: 247\n",
      "10002/video_features\\video_{ParticipantNo}_247_18-11-2020.csv\n",
      "processing pptnum: 248\n",
      "10002/video_features\\video_{ParticipantNo}_248_9-12-2020.csv\n",
      "processing pptnum: 250\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 251\n",
      "10002/video_features\\video_{ParticipantNo}_251_4-12-2020.csv\n",
      "processing pptnum: 252\n",
      "10002/video_features\\video_{ParticipantNo}_252_27-11-2020.csv\n",
      "processing pptnum: 253\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 254\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 255\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 255\n",
      "this file is not found - video present, but no openface file for 255\n",
      "processing pptnum: 256\n",
      "10002/video_features\\video_{ParticipantNo}_256_26-11-2020.csv\n",
      "processing pptnum: 258\n",
      "10002/video_features\\video_{ParticipantNo}_258_29-11-2020.csv\n",
      "processing pptnum: 260\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 261\n",
      "10002/video_features\\video_{ParticipantNo}_261_7-1-2021.csv\n",
      "processing pptnum: 263\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 265\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 266\n",
      "10002/video_features\\video_{ParticipantNo}_266_7-12-2020.csv\n",
      "processing pptnum: 269\n",
      "10002/video_features\\video_{ParticipantNo}_269_9-11-2020.csv\n",
      "processing pptnum: 271\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 273\n",
      "10002/video_features\\video_{ParticipantNo}_273_9-11-2020.csv\n",
      "processing pptnum: 274\n",
      "10002/video_features\\video_{ParticipantNo}_274_15-12-2020.csv\n",
      "processing pptnum: 275\n",
      "10002/video_features\\video_{ParticipantNo}_275_4-11-2020.csv\n",
      "processing pptnum: 277\n",
      "10002/video_features\\video_{ParticipantNo}_277_6-11-2020.csv\n",
      "processing pptnum: 279\n",
      "10002/video_features\\video_{ParticipantNo}_279_18-11-2020.csv\n",
      "processing pptnum: 280\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 282\n",
      "10002/video_features\\video_{ParticipantNo}_282_2-2-2021.csv\n",
      "processing pptnum: 283\n",
      "10002/video_features\\video_{ParticipantNo}_283_11-12-2020.csv\n",
      "processing pptnum: 286\n",
      "10002/video_features\\video_{ParticipantNo}_286_9-11-2020.csv\n",
      "processing pptnum: 290\n",
      "10002/video_features\\video_{ParticipantNo}_290_15-12-2020.csv\n",
      "processing pptnum: 293\n",
      "10002/video_features\\video_{ParticipantNo}_293_22-11-2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▍                                                                | 101/525 [00:07<00:30, 13.79it/s]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29732/1406656151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this file is not found - video present, but no openface file for '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpptnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                             \u001b[0mget_openfacestuff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileDir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29732/1416748208.py\u001b[0m in \u001b[0;36mget_openfacestuff\u001b[1;34m(fileDir)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AU12'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mredoOpenface\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Check if OpenFace values have already been added, of whether manually set at top of script to re do this (so it doesnt happen unneccessarily\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mopenface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileDir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ISO-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Read openface output csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# Get corresponding video file duration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pms_study\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# The BIG loop where all the magic happens\n",
    "\n",
    "index = 0\n",
    "for pptnum in tqdm(timings[\"pptnumber\"]): # Loop over all ppt's that had a video available (therefore present in timings.csv)\n",
    "    if '514' not in str(pptnum) and '583' not in str(pptnum) and '342' not in str(pptnum) and '4888' not in str(pptnum): # '&': This is something that gives errors, '383': Corrupted file, '467': same, '495': same, '502': same\n",
    "\n",
    "        print(\"processing pptnum: \" + str(pptnum))\n",
    "        idx = np.where(allData['ID'] == int(pptnum))[0] # Watch out; this will give you ALL indices for this pptnum, so both A and B\n",
    "        if timings[\"Exclusion\"][index] == 1: # Only continue the loop if there is no Exclusion marked\n",
    "            print(\"Exclusion file for ppt: \" + str(pptnum) + \" at moment: \" + timings[\"ImageGroup\"][index])\n",
    "        else:\n",
    "            videoOffset = float(timings[\"StartTime\"][index])\n",
    "            if videoOffset == 0: # if a timing start point was not present, it was set to 0. We don't process those because we cant sync them\n",
    "                print('start time for this ppt is set to zero')\n",
    "            else:\n",
    "                if len(idx) < 1: # Check if occurences in datafile exist for this participant/video file\n",
    "                    print(\"No input data found for video file of pptnum: \" + str(pptnum) + \" with video file \" + timings[\"ImageGroup\"][index] )\n",
    "                else:           \n",
    "                    moment = timings[\"ImageGroup\"][index]\n",
    "                    if moment ==  'A':\n",
    "                        indices = [i for i, s in enumerate(AFiles) if str(pptnum) in s]\n",
    "                        idx = np.where((allData['ID'] == int(pptnum)) & (allData['Moment'] == 'A'))[0] # So we don't also use the indices that don't apply here right now\n",
    "                        try:\n",
    "                            fileDir = AFiles[indices[0]]\n",
    "                        except:\n",
    "                            print('this file is not found - video present, but no openface file for ' + str(pptnum))\n",
    "                        else: \n",
    "                            get_openfacestuff(fileDir)\n",
    "                    elif moment == 'B':\n",
    "                        indices = [i for i, s in enumerate(BFiles) if str(pptnum) in s]\n",
    "                        idx = np.where((allData['ID'] == int(pptnum)) & (allData['Moment'] == 'B'))[0] # So we don't also use the indices that don't apply here right now\n",
    "                        try:\n",
    "                            fileDir = BFiles[indices[0]]\n",
    "                        except:\n",
    "                            print('this file is not found - video present, but no openface file for ' + str(pptnum))\n",
    "                        else: \n",
    "                            get_openfacestuff(fileDir)\n",
    "\n",
    "                    else:\n",
    "                        print(\"Some error with testing moment\")\n",
    "                        break\n",
    "\n",
    "    index += 1 # Create counter\n",
    "#     if index > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07b53d44-d34b-4f62-99d3-54c6a4272afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10002/video_features\\\\video_{ParticipantNo}_350_7-1-2021.csv'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileDir\n",
    "# index\n",
    "# timings[\"ImageGroup\"][index]\n",
    "# allData['Moment'][np.where((allData['ID'] == int(pptnum)))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "128ee37b-707e-4b2a-a00d-7f0226089ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33772/1946111052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AU12'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "math.isnan(allData['AU12'][idx[0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee50348-85c1-48d0-8471-89cd5508cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck me\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a03c68a0-624a-498b-95d9-f0200600977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1531"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2ed0bdd-91a5-4da4-8e94-a40a21cc9644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8360, 8361, 8362, 8363, 8364, 8365, 8366, 8367, 8368, 8369, 8370,\n",
       "       8371, 8372, 8373, 8374, 8375, 8376, 8377, 8378, 8379, 8380, 8381],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc58547-8a86-449d-8169-e813778e76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>FirstMenstrual</th>\n",
       "      <th>MenstrualDuration</th>\n",
       "      <th>Exclusie</th>\n",
       "      <th>TrueFollicular</th>\n",
       "      <th>TrueLuteal</th>\n",
       "      <th>Isala</th>\n",
       "      <th>Order</th>\n",
       "      <th>...</th>\n",
       "      <th>PD_Mean</th>\n",
       "      <th>PD_Std</th>\n",
       "      <th>PD_Max</th>\n",
       "      <th>headMovement</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>scared</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-11-2020</td>\n",
       "      <td>30-11-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-11-2020</td>\n",
       "      <td>30-11-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-11-2020</td>\n",
       "      <td>30-11-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-11-2020</td>\n",
       "      <td>30-11-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15-11-2020</td>\n",
       "      <td>30-11-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15835</th>\n",
       "      <td>15835</td>\n",
       "      <td>524</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-5-2021</td>\n",
       "      <td>18-5-2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15836</th>\n",
       "      <td>15836</td>\n",
       "      <td>524</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-5-2021</td>\n",
       "      <td>18-5-2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15837</th>\n",
       "      <td>15837</td>\n",
       "      <td>524</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-5-2021</td>\n",
       "      <td>18-5-2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15838</th>\n",
       "      <td>15838</td>\n",
       "      <td>524</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-5-2021</td>\n",
       "      <td>18-5-2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15839</th>\n",
       "      <td>15839</td>\n",
       "      <td>524</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-5-2021</td>\n",
       "      <td>18-5-2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15840 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   ID  Age  FirstMenstrual  MenstrualDuration  Exclusie  \\\n",
       "0               0  201   44              12                 29       NaN   \n",
       "1               1  201   44              12                 29       NaN   \n",
       "2               2  201   44              12                 29       NaN   \n",
       "3               3  201   44              12                 29       NaN   \n",
       "4               4  201   44              12                 29       NaN   \n",
       "...           ...  ...  ...             ...                ...       ...   \n",
       "15835       15835  524   30              12                 29       NaN   \n",
       "15836       15836  524   30              12                 29       NaN   \n",
       "15837       15837  524   30              12                 29       NaN   \n",
       "15838       15838  524   30              12                 29       NaN   \n",
       "15839       15839  524   30              12                 29       NaN   \n",
       "\n",
       "      TrueFollicular  TrueLuteal Isala Order  ... PD_Mean PD_Std  PD_Max  \\\n",
       "0         15-11-2020  30-11-2020   NaN   A-B  ...     NaN    NaN     NaN   \n",
       "1         15-11-2020  30-11-2020   NaN   A-B  ...     NaN    NaN     NaN   \n",
       "2         15-11-2020  30-11-2020   NaN   A-B  ...     NaN    NaN     NaN   \n",
       "3         15-11-2020  30-11-2020   NaN   A-B  ...     NaN    NaN     NaN   \n",
       "4         15-11-2020  30-11-2020   NaN   A-B  ...     NaN    NaN     NaN   \n",
       "...              ...         ...   ...   ...  ...     ...    ...     ...   \n",
       "15835       3-5-2021   18-5-2021   NaN   B-A  ...     NaN    NaN     NaN   \n",
       "15836       3-5-2021   18-5-2021   NaN   B-A  ...     NaN    NaN     NaN   \n",
       "15837       3-5-2021   18-5-2021   NaN   B-A  ...     NaN    NaN     NaN   \n",
       "15838       3-5-2021   18-5-2021   NaN   B-A  ...     NaN    NaN     NaN   \n",
       "15839       3-5-2021   18-5-2021   NaN   B-A  ...     NaN    NaN     NaN   \n",
       "\n",
       "       headMovement  happy  sad  disgust  anger  scared  confidence  \n",
       "0               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "1               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "2               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "3               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "4               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "...             ...    ...  ...      ...    ...     ...         ...  \n",
       "15835           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15836           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15837           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15838           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15839           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "\n",
       "[15840 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e36113-c80c-49b1-90a9-7da2e9593fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.join(data_dir,date_dir))\n",
    "# allData.to_csv('allPMSdata3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a4e03f-d64c-4de9-b451-0a976f4a9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.to_csv(str(data_dir) + '\\\\' + str(date_dir) + 'allPMSdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f721086-ef96-4323-afff-ed11f90a38cc",
   "metadata": {},
   "source": [
    "# Where to start when stuff goes wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f581822-3487-4bec-996a-49686da710e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openface = pd.read_csv(fileDir, encoding = \"ISO-8859-1\") # Read openface output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbc35a-0895-46c8-90bb-bbdb5a78647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get corresponding video file duration \n",
    "splits = fileDir.split('/video_features\\\\')\n",
    "fileduration = [value for key, value in durationsdata.items() if splits[0] in key.lower() and splits[1][23:len(splits[1])-4] in key.lower()] # Very weird formatting, but when checking for directory (10001/10002) and only the date (something with curly bracktes messes it up. \n",
    "frameduration = fileduration[0] / len(openface)\n",
    "openface.insert (3, \"timestamp2\", np.arange(0, fileduration[0], frameduration).tolist()[0:len(openface)]) # Add new timestamps right after the first timestamp || We're taking [0:len(openface)] here because due to rounding error, the newly created timestamps might be one longer than th array. \n",
    "videoOffset\n",
    "behaviorOffset = allData['startBeep'][idx[0]]\n",
    "correctedStarts = allData['startView'][idx] - behaviorOffset # startViews - offSet\n",
    "videoStarts = ((correctedStarts + videoOffset) / 1000).tolist() # These will be the timestamps in seconds because / 1000\n",
    "\n",
    "correctedEnds = allData['stopView'][idx] - behaviorOffset # startViews - offSet\n",
    "videoEnds = ((correctedEnds + videoOffset) / 1000).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b725ff-4746-424f-bf3c-f7705ef74d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx\n",
    "videoStarts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
