{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a599427c-70ba-42e3-85fd-dca7d7d7f116",
   "metadata": {},
   "source": [
    "# What's happening here?\n",
    "\n",
    "4_link_video_behavior.ipynb\n",
    "\n",
    "Run after 1_, 2_, and 3_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e3393-2206-400e-9b4f-e97860ffc57b",
   "metadata": {},
   "source": [
    "Made in environment **PMS_Study**\n",
    "\n",
    "## TO DO: bekijk file PMS_analysis/2_preparation\n",
    "\n",
    "Probeer veel met loops en functions te werken om de code overzichtelijk te houden\n",
    "\n",
    " * Start with file cleanData.csv (geeft informatie over van welke participant welke files bestaan)\n",
    " * Load timings.csv file that Tilia and Sofie made\n",
    " * Start loop from the top and use Order and A-B\n",
    " * In loop check if file (corresponding CSV) exists in Directory (/10001 or /10002 depedent of A/B): later refered to as behaviordata\n",
    " * In loop check if file (corresponding .WEBM) exists in Directory\n",
    " \n",
    "If both exist:\n",
    "- Check if output of Openface exists in Z:\\shares\\ghepmk_data\\2020_Kappen_PMS\\10002\\video_features (or /10001 dependent of A/B)\n",
    "- IF True:\n",
    "Load this as facedata\n",
    "- IF False:\n",
    "Print: \"Video file present for file (insert filename) but no openface present)\"\n",
    "Break/skip\n",
    "\n",
    "Use filename/pptnum to search for right starting time in timings.csv variable\n",
    "- Find timing for beep.wav in behaviordata. \n",
    "- Set new zero point (link between the timings.csv point and this)\n",
    "- Make mean scores on a few variables (we will expand this later) for the corresponding frames of each of the trials.\n",
    "- To do this, you should write a function that takes the right points of a trial (start, end, trialnum etc) and save this data to a dataframe\n",
    "\n",
    "Compute this in a way that you would be able to add it to allPMSdata.cvs\n",
    "\n",
    "Add it all to a new dataframe\n",
    "\n",
    "Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5439c6-64af-4bc7-9e84-900f8dfb6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "import features as ft\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e11c38-e968-46b7-8f43-fa5976c54e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all relevant directories\n",
    "data_dir = Path('Z:/shares/ghepmk_data/2020_Kappen_PMS')\n",
    "date_dir = \"06102021/\"\n",
    "data_all_dir = os.path.join(data_dir, date_dir)\n",
    "\n",
    "# Load base data\n",
    "demographics = pd.read_csv(data_all_dir + \"cleanData.csv\", encoding = \"ISO-8859-1\")\n",
    "allData = pd.read_csv(data_all_dir + \"allPMSdata3.csv\", encoding = \"ISO-8859-1\")\n",
    "timings = pd.read_csv(data_all_dir + \"timings.csv\", encoding = \"ISO-8859-1\")\n",
    "timings = timings.rename(columns={\"ï»¿ImageGroup\": \"ImageGroup\"}, index={'ONE': 'Row_1'}) # Rename first column, because was formatted weird\n",
    "\n",
    "redoOpenface = 1 # Set to 1 if you want to re-do OpenFace processing. For instance if you added features, or changed methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c9098d-fc3a-4451-ad0c-d330c5e8ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all OpenFace files\n",
    "os.chdir(data_dir)\n",
    "AFiles = glob.glob(\"10001/video_features/\" + \"*ParticipantNo*\" + \"*.csv\", recursive = True) # get all csv's in directory\n",
    "BFiles = glob.glob(\"10002/video_features/\" + \"*ParticipantNo*\" + \"*.csv\", recursive = True) # get all csv's in directory\n",
    "\n",
    "# Opening JSON file with all video duration information\n",
    "f = open(data_all_dir + 'video_durations.json',)\n",
    "durationsdata = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fce032a-3a1c-4259-88ac-f66c1c95d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openfacestuff(fileDir):\n",
    "    print(fileDir)\n",
    "    if len(indices) > 1:\n",
    "        print(\"Too many OpenFace files for ppt: \" + str(pptnum) + \" at moment \" + moment)\n",
    "    else: # If we get to here - the party really starts\n",
    "        try:\n",
    "            math.isnan(allData['AU12'][idx[0]])\n",
    "        except:\n",
    "            allData[\"AU12\"] = np.nan # In case this column doesn't exist yet, create a column with only nan's so th next if statement always passes\n",
    "            \n",
    "        if math.isnan(allData['AU12'][idx[0]]) or redoOpenface == 1: # Check if OpenFace values have already been added, of whether manually set at top of script to re do this (so it doesnt happen unneccessarily\n",
    "            openface = pd.read_csv(fileDir, encoding = \"ISO-8859-1\") # Read openface output csv\n",
    "\n",
    "            # Get corresponding video file duration \n",
    "            splits = fileDir.split('/video_features\\\\')\n",
    "            fileduration = [value for key, value in durationsdata.items() if splits[0] in key.lower() and splits[1][23:len(splits[1])-4] in key.lower()] # Very weird formatting, but when checking for directory (10001/10002) and only the date (something with curly bracktes messes it up. \n",
    "            frameduration = fileduration[0] / len(openface)\n",
    "            openface.insert (3, \"timestamp2\", np.arange(0, fileduration[0], frameduration).tolist()[0:len(openface)]) # Add new timestamps right after the first timestamp || We're taking [0:len(openface)] here because due to rounding error, the newly created timestamps might be one longer than th array. \n",
    "            videoOffset\n",
    "            behaviorOffset = allData['startBeep'][idx[0]]\n",
    "            correctedStarts = allData['startView'][idx] - behaviorOffset # startViews - offSet\n",
    "            videoStarts = ((correctedStarts + videoOffset) / 1000).tolist() # These will be the timestamps in seconds because / 1000\n",
    "\n",
    "            correctedEnds = allData['stopView'][idx] - behaviorOffset # startViews - offSet\n",
    "            videoEnds = ((correctedEnds + videoOffset) / 1000).tolist()\n",
    "\n",
    "            # Loop over all the trials and get the appropriate values - add to allData\n",
    "            for trial in range(0,len(videoStarts)):\n",
    "                vidStartIdx = openface.iloc[(openface['timestamp2']-videoStarts[trial]).abs().argsort()[:1]].index.tolist()[0] # Get start idx in openface\n",
    "                vidEndIdx = openface.iloc[(openface['timestamp2']-videoEnds[trial]).abs().argsort()[:1]].index.tolist()[0] # Get end idx in openface\n",
    "\n",
    "                # Create mean value between these idx's and add to big dataframe\n",
    "                allData.loc[idx[trial], 'AU12'] = openface[' AU12_r'][vidStartIdx:vidEndIdx].mean() \n",
    "                allData.loc[idx[trial], 'AU15'] = openface[' AU15_r'][vidStartIdx:vidEndIdx].mean() \n",
    "                \n",
    "                allData.loc[idx[trial], 'arousal'] = ft.compute_arousal(openface[vidStartIdx:vidEndIdx])['mean_Arousal']\n",
    "                allData.loc[idx[trial], 'blinkrate'] = ft.compute_blink_rate(openface[vidStartIdx:vidEndIdx])\n",
    "                allData.loc[idx[trial], 'PD_Mean'] = ft.compute_PD_features(openface[vidStartIdx:vidEndIdx])['mean_PD']\n",
    "                allData.loc[idx[trial], 'PD_Std'] = ft.compute_PD_features(openface[vidStartIdx:vidEndIdx])['std_PD']\n",
    "                allData.loc[idx[trial], 'PD_Max'] = ft.compute_PD_features(openface[vidStartIdx:vidEndIdx])['max_PD']\n",
    "                \n",
    "                allData.loc[idx[trial], 'headMovement'] = ft.compute_head_motion(openface[vidStartIdx:vidEndIdx])['compound_Motion']\n",
    "\n",
    "                allData.loc[idx[trial], 'happy'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Happy']\n",
    "                allData.loc[idx[trial], 'sad'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Sad']\n",
    "                allData.loc[idx[trial], 'disgust'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Disgust']\n",
    "                allData.loc[idx[trial], 'anger'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Angry']\n",
    "                allData.loc[idx[trial], 'scared'] = ft.compute_emotions(openface[vidStartIdx:vidEndIdx])['mean_Scared']\n",
    "                \n",
    "                allData.loc[idx[trial], 'confidence'] = ft.compute_quality(openface[vidStartIdx:vidEndIdx])['mean_confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07249d9e-24e6-4978-b21d-039f5c6df973",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/525 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing pptnum: 14\n",
      "Exclusion file for ppt: 14 at moment: B\n",
      "processing pptnum: 66\n",
      "Exclusion file for ppt: 66 at moment: B\n",
      "processing pptnum: 106\n",
      "No input data found for video file of pptnum: 106 with video file B\n",
      "processing pptnum: 119\n",
      "No input data found for video file of pptnum: 119 with video file B\n",
      "processing pptnum: 123\n",
      "No input data found for video file of pptnum: 123 with video file B\n",
      "processing pptnum: 124\n",
      "No input data found for video file of pptnum: 124 with video file B\n",
      "processing pptnum: 125\n",
      "No input data found for video file of pptnum: 125 with video file B\n",
      "processing pptnum: 126\n",
      "No input data found for video file of pptnum: 126 with video file B\n",
      "processing pptnum: 127\n",
      "start time for this ppt is set to zero\n",
      "processing pptnum: 129\n",
      "10002/video_features\\video_{ParticipantNo}_129_9-10-2020.csv\n"
     ]
    }
   ],
   "source": [
    "# The BIG loop where all the magic happens\n",
    "\n",
    "index = 0\n",
    "for pptnum in tqdm(timings[\"pptnumber\"]): # Loop over all ppt's that had a video available (therefore present in timings.csv)\n",
    "    if '514' not in str(pptnum) and '583' not in str(pptnum) and '342' not in str(pptnum) and '4888' not in str(pptnum): # '&': This is something that gives errors, '383': Corrupted file, '467': same, '495': same, '502': same\n",
    "\n",
    "        print(\"processing pptnum: \" + str(pptnum))\n",
    "        idx = np.where(allData['ID'] == int(pptnum))[0]\n",
    "        if timings[\"Exclusion\"][index] == 1: # Only continue the loop if there is no Exclusion marked\n",
    "            print(\"Exclusion file for ppt: \" + str(pptnum) + \" at moment: \" + timings[\"ImageGroup\"][index])\n",
    "        else:\n",
    "            videoOffset = float(timings[\"StartTime\"][index])\n",
    "            if videoOffset == 0: # if a timing start point was not present, it was set to 0. We don't process those because we cant sync them\n",
    "                print('start time for this ppt is set to zero')\n",
    "            else:\n",
    "                if len(idx) < 1: # Check if occurences in datafile exist for this participant/video file\n",
    "                    print(\"No input data found for video file of pptnum: \" + str(pptnum) + \" with video file \" + timings[\"ImageGroup\"][index] )\n",
    "                else:           \n",
    "                    moment = timings[\"ImageGroup\"][index]\n",
    "                    if moment ==  'A':\n",
    "                        indices = [i for i, s in enumerate(AFiles) if str(pptnum) in s]\n",
    "                        try:\n",
    "                            fileDir = AFiles[indices[0]]\n",
    "                        except:\n",
    "                            print('this file is not found - video present, but no openface file for ' + str(pptnum))\n",
    "                        else: \n",
    "                            get_openfacestuff(fileDir)\n",
    "                    elif moment == 'B':\n",
    "                        indices = [i for i, s in enumerate(BFiles) if str(pptnum) in s]\n",
    "                        try:\n",
    "                            fileDir = BFiles[indices[0]]\n",
    "                        except:\n",
    "                            print('this file is not found - video present, but no openface file for ' + str(pptnum))\n",
    "                        else: \n",
    "                            get_openfacestuff(fileDir)\n",
    "\n",
    "                    else:\n",
    "                        print(\"Some error with testing moment\")\n",
    "                        break\n",
    "\n",
    "    index += 1 # Create counter\n",
    "#     if index > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc58547-8a86-449d-8169-e813778e76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>FirstMenstrual</th>\n",
       "      <th>MenstrualDuration</th>\n",
       "      <th>Exclusie</th>\n",
       "      <th>TrueFollicular</th>\n",
       "      <th>TrueLuteal</th>\n",
       "      <th>Isala</th>\n",
       "      <th>Order</th>\n",
       "      <th>...</th>\n",
       "      <th>PD_Mean</th>\n",
       "      <th>PD_Std</th>\n",
       "      <th>PD_Max</th>\n",
       "      <th>headMovement</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>scared</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-12-2020</td>\n",
       "      <td>19-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-12-2020</td>\n",
       "      <td>19-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-12-2020</td>\n",
       "      <td>19-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>165</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-12-2020</td>\n",
       "      <td>19-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-12-2020</td>\n",
       "      <td>19-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15857</th>\n",
       "      <td>15857</td>\n",
       "      <td>535</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7-5-2021</td>\n",
       "      <td>16-5-2021</td>\n",
       "      <td>03660</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15858</th>\n",
       "      <td>15858</td>\n",
       "      <td>535</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7-5-2021</td>\n",
       "      <td>16-5-2021</td>\n",
       "      <td>03660</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>15859</td>\n",
       "      <td>535</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7-5-2021</td>\n",
       "      <td>16-5-2021</td>\n",
       "      <td>03660</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>15860</td>\n",
       "      <td>535</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7-5-2021</td>\n",
       "      <td>16-5-2021</td>\n",
       "      <td>03660</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15861</th>\n",
       "      <td>15861</td>\n",
       "      <td>535</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7-5-2021</td>\n",
       "      <td>16-5-2021</td>\n",
       "      <td>03660</td>\n",
       "      <td>A-B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15862 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   ID  Age  FirstMenstrual  MenstrualDuration  Exclusie  \\\n",
       "0               0  165   21              16                 28       NaN   \n",
       "1               1  165   21              16                 28       NaN   \n",
       "2               2  165   21              16                 28       NaN   \n",
       "3               3  165   21              16                 28       NaN   \n",
       "4               4  165   21              16                 28       NaN   \n",
       "...           ...  ...  ...             ...                ...       ...   \n",
       "15857       15857  535   32              13                 23       NaN   \n",
       "15858       15858  535   32              13                 23       NaN   \n",
       "15859       15859  535   32              13                 23       NaN   \n",
       "15860       15860  535   32              13                 23       NaN   \n",
       "15861       15861  535   32              13                 23       NaN   \n",
       "\n",
       "      TrueFollicular  TrueLuteal  Isala Order  ... PD_Mean PD_Std  PD_Max  \\\n",
       "0          5-12-2020  19-12-2020    NaN   B-A  ...     NaN    NaN     NaN   \n",
       "1          5-12-2020  19-12-2020    NaN   B-A  ...     NaN    NaN     NaN   \n",
       "2          5-12-2020  19-12-2020    NaN   B-A  ...     NaN    NaN     NaN   \n",
       "3          5-12-2020  19-12-2020    NaN   B-A  ...     NaN    NaN     NaN   \n",
       "4          5-12-2020  19-12-2020    NaN   B-A  ...     NaN    NaN     NaN   \n",
       "...              ...         ...    ...   ...  ...     ...    ...     ...   \n",
       "15857       7-5-2021   16-5-2021  03660   A-B  ...     NaN    NaN     NaN   \n",
       "15858       7-5-2021   16-5-2021  03660   A-B  ...     NaN    NaN     NaN   \n",
       "15859       7-5-2021   16-5-2021  03660   A-B  ...     NaN    NaN     NaN   \n",
       "15860       7-5-2021   16-5-2021  03660   A-B  ...     NaN    NaN     NaN   \n",
       "15861       7-5-2021   16-5-2021  03660   A-B  ...     NaN    NaN     NaN   \n",
       "\n",
       "       headMovement  happy  sad  disgust  anger  scared  confidence  \n",
       "0               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "1               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "2               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "3               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "4               NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "...             ...    ...  ...      ...    ...     ...         ...  \n",
       "15857           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15858           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15859           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15860           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "15861           NaN    NaN  NaN      NaN    NaN     NaN         NaN  \n",
       "\n",
       "[15862 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e36113-c80c-49b1-90a9-7da2e9593fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.join(data_dir,date_dir))\n",
    "# allData.to_csv('allPMSdata3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a4e03f-d64c-4de9-b451-0a976f4a9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.to_csv(str(data_dir) + '\\\\' + str(date_dir) + 'allPMSdata3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30124226-ed78-498f-880d-21ec684794b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
